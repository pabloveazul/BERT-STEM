{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2187daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pablouribepizarro/Documents/GitHub/BERT-STEM\n",
      "/Users/pablouribepizarro/Documents/GitHub/BERT-STEM/src\n",
      "/Users/pablouribepizarro/Documents/GitHub/BERT-STEM/src/BERT_STEM\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd src\n",
    "%cd BERT_STEM\n",
    "from BERT_STEM.Encode import *\n",
    "import BertSTEM\n",
    "import pandas as pd\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f6059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Download spanish BERT:\n",
    "model = transformers.BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef779df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download spanish tokenizer:\n",
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\",do_lower_case=True, add_special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e025d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataframe with text in spanish\n",
    "data = {'col_1': [3, 2, 1], \n",
    "        'col_2': ['hola como estan', 'alumnos queridos', 'vamos a hablar de matematicas']}\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66a81ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>SUM_0</th>\n",
       "      <th>SUM_1</th>\n",
       "      <th>SUM_2</th>\n",
       "      <th>SUM_3</th>\n",
       "      <th>SUM_4</th>\n",
       "      <th>SUM_5</th>\n",
       "      <th>SUM_6</th>\n",
       "      <th>SUM_7</th>\n",
       "      <th>...</th>\n",
       "      <th>SUM_758</th>\n",
       "      <th>SUM_759</th>\n",
       "      <th>SUM_760</th>\n",
       "      <th>SUM_761</th>\n",
       "      <th>SUM_762</th>\n",
       "      <th>SUM_763</th>\n",
       "      <th>SUM_764</th>\n",
       "      <th>SUM_765</th>\n",
       "      <th>SUM_766</th>\n",
       "      <th>SUM_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>hola como estan</td>\n",
       "      <td>-1.700786</td>\n",
       "      <td>-1.760625</td>\n",
       "      <td>1.967040</td>\n",
       "      <td>-2.899785</td>\n",
       "      <td>2.762954</td>\n",
       "      <td>-1.017555</td>\n",
       "      <td>0.548983</td>\n",
       "      <td>-1.160371</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.562262</td>\n",
       "      <td>3.154655</td>\n",
       "      <td>1.552447</td>\n",
       "      <td>-3.136322</td>\n",
       "      <td>-3.724271</td>\n",
       "      <td>-1.145931</td>\n",
       "      <td>4.428095</td>\n",
       "      <td>0.207791</td>\n",
       "      <td>5.901742</td>\n",
       "      <td>-1.490143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alumnos queridos</td>\n",
       "      <td>1.337676</td>\n",
       "      <td>-2.040652</td>\n",
       "      <td>3.120281</td>\n",
       "      <td>0.445535</td>\n",
       "      <td>1.834115</td>\n",
       "      <td>1.943148</td>\n",
       "      <td>3.511281</td>\n",
       "      <td>2.248597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.839623</td>\n",
       "      <td>-2.212891</td>\n",
       "      <td>-1.991792</td>\n",
       "      <td>-5.451099</td>\n",
       "      <td>-0.581947</td>\n",
       "      <td>-2.032886</td>\n",
       "      <td>1.143040</td>\n",
       "      <td>1.079169</td>\n",
       "      <td>2.019759</td>\n",
       "      <td>3.394125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>vamos a hablar de matematicas</td>\n",
       "      <td>-0.593493</td>\n",
       "      <td>6.140261</td>\n",
       "      <td>7.451053</td>\n",
       "      <td>-2.412131</td>\n",
       "      <td>-2.278517</td>\n",
       "      <td>5.188994</td>\n",
       "      <td>-3.946751</td>\n",
       "      <td>-9.876625</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.920628</td>\n",
       "      <td>0.816847</td>\n",
       "      <td>1.259655</td>\n",
       "      <td>-5.159519</td>\n",
       "      <td>-6.839560</td>\n",
       "      <td>4.979477</td>\n",
       "      <td>-2.389618</td>\n",
       "      <td>0.460332</td>\n",
       "      <td>-0.194753</td>\n",
       "      <td>1.463782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_1                          col_2     SUM_0     SUM_1     SUM_2  \\\n",
       "0      3                hola como estan -1.700786 -1.760625  1.967040   \n",
       "1      2               alumnos queridos  1.337676 -2.040652  3.120281   \n",
       "2      1  vamos a hablar de matematicas -0.593493  6.140261  7.451053   \n",
       "\n",
       "      SUM_3     SUM_4     SUM_5     SUM_6     SUM_7  ...   SUM_758   SUM_759  \\\n",
       "0 -2.899785  2.762954 -1.017555  0.548983 -1.160371  ... -6.562262  3.154655   \n",
       "1  0.445535  1.834115  1.943148  3.511281  2.248597  ... -0.839623 -2.212891   \n",
       "2 -2.412131 -2.278517  5.188994 -3.946751 -9.876625  ... -3.920628  0.816847   \n",
       "\n",
       "    SUM_760   SUM_761   SUM_762   SUM_763   SUM_764   SUM_765   SUM_766  \\\n",
       "0  1.552447 -3.136322 -3.724271 -1.145931  4.428095  0.207791  5.901742   \n",
       "1 -1.991792 -5.451099 -0.581947 -2.032886  1.143040  1.079169  2.019759   \n",
       "2  1.259655 -5.159519 -6.839560  4.979477 -2.389618  0.460332 -0.194753   \n",
       "\n",
       "    SUM_767  \n",
       "0 -1.490143  \n",
       "1  3.394125  \n",
       "2  1.463782  \n",
       "\n",
       "[3 rows x 770 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoder(df, model, tokenizer, column = 'col_2', encoding = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66352d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6d9d23cb83414f81401aef72e16f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/682 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d70a1247324782866fab3138fd0771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pablouribe/bertstem were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = BertSTEM.BertSTEM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082bd1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>SUM_0</th>\n",
       "      <th>SUM_1</th>\n",
       "      <th>SUM_2</th>\n",
       "      <th>SUM_3</th>\n",
       "      <th>SUM_4</th>\n",
       "      <th>SUM_5</th>\n",
       "      <th>SUM_6</th>\n",
       "      <th>SUM_7</th>\n",
       "      <th>...</th>\n",
       "      <th>SUM_758</th>\n",
       "      <th>SUM_759</th>\n",
       "      <th>SUM_760</th>\n",
       "      <th>SUM_761</th>\n",
       "      <th>SUM_762</th>\n",
       "      <th>SUM_763</th>\n",
       "      <th>SUM_764</th>\n",
       "      <th>SUM_765</th>\n",
       "      <th>SUM_766</th>\n",
       "      <th>SUM_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>hola como estan</td>\n",
       "      <td>0.411079</td>\n",
       "      <td>0.283486</td>\n",
       "      <td>-3.296653</td>\n",
       "      <td>5.061632</td>\n",
       "      <td>3.138548</td>\n",
       "      <td>-2.016285</td>\n",
       "      <td>1.303340</td>\n",
       "      <td>-4.087291</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.619895</td>\n",
       "      <td>3.281078</td>\n",
       "      <td>5.614406</td>\n",
       "      <td>-6.370847</td>\n",
       "      <td>-4.959441</td>\n",
       "      <td>-1.930010</td>\n",
       "      <td>6.829390</td>\n",
       "      <td>0.564994</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>0.227308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alumnos queridos</td>\n",
       "      <td>1.199810</td>\n",
       "      <td>-0.003853</td>\n",
       "      <td>-1.039371</td>\n",
       "      <td>2.068959</td>\n",
       "      <td>-1.251455</td>\n",
       "      <td>2.797794</td>\n",
       "      <td>1.284355</td>\n",
       "      <td>1.174224</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434632</td>\n",
       "      <td>0.839123</td>\n",
       "      <td>1.391374</td>\n",
       "      <td>-2.810407</td>\n",
       "      <td>-3.208865</td>\n",
       "      <td>0.865432</td>\n",
       "      <td>3.030386</td>\n",
       "      <td>0.560964</td>\n",
       "      <td>3.646884</td>\n",
       "      <td>-2.712711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>vamos a hablar de matematicas</td>\n",
       "      <td>-6.378608</td>\n",
       "      <td>5.055726</td>\n",
       "      <td>1.099216</td>\n",
       "      <td>-3.472992</td>\n",
       "      <td>6.890693</td>\n",
       "      <td>3.606877</td>\n",
       "      <td>-8.846287</td>\n",
       "      <td>-10.214820</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.202124</td>\n",
       "      <td>4.476853</td>\n",
       "      <td>2.769633</td>\n",
       "      <td>-2.514848</td>\n",
       "      <td>-7.248503</td>\n",
       "      <td>-6.677787</td>\n",
       "      <td>-6.655005</td>\n",
       "      <td>-4.047309</td>\n",
       "      <td>1.109065</td>\n",
       "      <td>-9.582942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_1                          col_2     SUM_0     SUM_1     SUM_2  \\\n",
       "0      3                hola como estan  0.411079  0.283486 -3.296653   \n",
       "1      2               alumnos queridos  1.199810 -0.003853 -1.039371   \n",
       "2      1  vamos a hablar de matematicas -6.378608  5.055726  1.099216   \n",
       "\n",
       "      SUM_3     SUM_4     SUM_5     SUM_6      SUM_7  ...   SUM_758   SUM_759  \\\n",
       "0  5.061632  3.138548 -2.016285  1.303340  -4.087291  ... -2.619895  3.281078   \n",
       "1  2.068959 -1.251455  2.797794  1.284355   1.174224  ...  1.434632  0.839123   \n",
       "2 -3.472992  6.890693  3.606877 -8.846287 -10.214820  ... -4.202124  4.476853   \n",
       "\n",
       "    SUM_760   SUM_761   SUM_762   SUM_763   SUM_764   SUM_765   SUM_766  \\\n",
       "0  5.614406 -6.370847 -4.959441 -1.930010  6.829390  0.564994 -0.054843   \n",
       "1  1.391374 -2.810407 -3.208865  0.865432  3.030386  0.560964  3.646884   \n",
       "2  2.769633 -2.514848 -7.248503 -6.677787 -6.655005 -4.047309  1.109065   \n",
       "\n",
       "    SUM_767  \n",
       "0  0.227308  \n",
       "1 -2.712711  \n",
       "2 -9.582942  \n",
       "\n",
       "[3 rows x 770 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert._encode_df(df, column='col_2', encoding='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbb978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
